---
  - name: verify hostname
    fail: msg="provided hostname does not match reported hostname of {{ ansible_nodename }}"
    when: "ansible_nodename not in [ inventory_hostname, inventory_hostname_short ]"
    changed_when: false

  - name: verify systemd
    fail: msg="systemd is required"
    when: ansible_service_mgr != "systemd"
    changed_when: false

  # Every etcd node should be able to reach all etcd nodes. This is quadratic,
  # but we can live with it because etcd count is usually <= 5
  - name: verify etcd to etcd node connectivity using IP
    command: ping -c 2 {{ item }}
    # Using map here to get the right item shown in stdout
    with_items: "{{ groups['etcd']|map('extract', hostvars, 'internal_ipv4')|list }}"
    when: "'etcd' in group_names"
  - name: verify etcd to etcd node connectivity using hostname
    command: ping -c 2 {{ item }}
    with_items: "{{ groups['etcd'] }}"
    when: "'etcd' in group_names"

  # Every master node should be able to reach all etcd nodes
  - name: verify master node to etcd node connectivity using IP
    command: ping -c 2 {{ item }}
    with_items: "{{ groups['etcd']|map('extract', hostvars, 'internal_ipv4')|list }}"
    when: "'master' in group_names"
  - name: verify master node to etcd node connectivity using hostname
    command: ping -c 2 {{ item }}
    with_items: "{{ groups['etcd'] }}"
    when: "'master' in group_names"

  # Every worker node should be able to reach all master nodes
  - name: verify worker node to master node connectivity using IP
    command: ping -c 2 {{ item }}
    with_items: "{{ groups['master']|map('extract', hostvars, 'internal_ipv4')|list }}"
    when: "'worker' in group_names"
  - name: verify worker node to master node connectivity using hostname
    command: ping -c 2 {{ item }}
    with_items: "{{ groups['master'] }}"
    when: "'worker' in group_names"

  # Every ingress node should be able to reach all master nodes
  - name: verify ingress node to master node connectivity using IP
    command: ping -c 2 {{ item }}
    with_items: "{{ groups['master']|map('extract', hostvars, 'internal_ipv4')|list }}"
    when: "'ingress' in group_names"
  - name: verify ingress node to master node connectivity using hostname
    command: ping -c 2 {{ item }}
    with_items: "{{ groups['master'] }}"
    when: "'ingress' in group_names"

  # Every ingress node should be able to reach all worker nodes
  - name: verify ingress node to worker node connectivity using IP
    command: ping -c 2 {{ item }}
    with_items: "{{ groups['worker']|map('extract', hostvars, 'internal_ipv4')|list }}"
    when: "'ingress' in group_names"
  - name: verify ingress node to worker node connectivity using hostname
    command: ping -c 2 {{ item }}
    with_items: "{{ groups['worker'] }}"
    when: "'ingress' in group_names"

  # Every worker node should be able to reach all worker nodes.
  # We use a random sampling of worker nodes to avoid quadratic complexity.
  - name: verify worker to worker node connectivity with random sample
    include: random_ping.yaml
    with_items: # Ping three nodes at random
      - 1
      - 2
      - 3
    loop_control:
      loop_var: outer_item # Define this (even thought we don't use it) so that ansible doesn't complain.
    when: "'worker' in group_names"

  - name: Validate devicemapper direct-lvm block device
    include: direct_lvm_preflight.yaml
    when: "ansible_os_family == 'RedHat' and docker_direct_lvm_enabled|bool == true and ('master' in group_names or 'worker' in group_names or 'ingress' in group_names or 'storage' in group_names)"

  # setup Kismatic Inspector
  - name: copy Kismatic Inspector to node
    copy:
      src: "{{ kismatic_preflight_checker }}"
      dest: "{{ bin_dir }}/kismatic-inspector"
      mode: 0744

  - name: copy kismatic-inspector.service to remote
    template:
      src: kismatic-inspector.service.j2
      dest: "{{ init_system_dir }}/kismatic-inspector.service"
    notify:
      - reload services

  - meta: flush_handlers  #Run handlers

  - name: start kismatic-inspector service
    service:
      name: kismatic-inspector.service
      state: restarted # always restart to ensure that any existing inspectors are replaced by this one

  # Run the pre-flights checks, and always stop the checker regardless of result
  - block:
      - name: run pre-flight checks using Kismatic Inspector
        local_action: command '{{ kismatic_preflight_checker_local | default(kismatic_preflight_checker) }}' client {{ ansible_host }}:8888 -o json --node-roles {{ ",".join(group_names) }}
        register: out
        become: no
    rescue: # Need to repeat because of Ansible bug https://github.com/ansible/ansible/issues/18602
      - name: stop kismatic-inspector service
        service:
          name: kismatic-inspector.service
          state: stopped
      - name: verify Kismatic Inspector succeeded
        command: /bin/true
        failed_when: "out.rc != 0"
    always:
      - name: stop kismatic-inspector service
        service:
          name: kismatic-inspector.service
          state: stopped
      - name: verify Kismatic Inspector succeeded
        command: /bin/true
        failed_when: "out.rc != 0"
